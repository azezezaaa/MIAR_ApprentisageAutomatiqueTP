{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "R&D Spend  Administration  Marketing Spend       State     Profit\n0  165349.20       136897.80        471784.10    New York  192261.83\n1  162597.70       151377.59        443898.53  California  191792.06\n2  153441.51       101145.55        407934.54     Florida  191050.39\n3  144372.41       118671.85        383199.62    New York  182901.99\n4  142107.34        91391.77        366168.42     Florida  166187.94\n"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset_original = pd.read_csv('50_Startups.csv')\n",
    "dataset = dataset_original.copy()\n",
    "print(dataset.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50 entries, 0 to 49\nData columns (total 5 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   R&D Spend        50 non-null     float64\n 1   Administration   50 non-null     float64\n 2   Marketing Spend  50 non-null     float64\n 3   State            50 non-null     object \n 4   Profit           50 non-null     float64\ndtypes: float64(4), object(1)\nmemory usage: 2.1+ KB\nDataset shape: (50, 5)\n"
    }
   ],
   "source": [
    "dataset.info()\n",
    "print('Dataset shape: ', dataset.shape, sep=\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                 Missing values  % of Total values\nProfit                        0                0.0\nState                         0                0.0\nMarketing Spend               0                0.0\nAdministration                0                0.0\nR&D Spend                     0                0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Missing values</th>\n      <th>% of Total values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Profit</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>State</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Marketing Spend</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Administration</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>R&amp;D Spend</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# Finding how many missing data are there in the dataset\n",
    "total = dataset.isnull().sum().sort_values(ascending=False)\n",
    "percent = round(((dataset.isnull().sum() / dataset.isnull().count())*100),2).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Missing values', '% of Total values'])\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values  # or dataset.iloc[:, [0,1,2,3]].values\n",
    "y = dataset.iloc[:, 4].values  # take the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[165349.2, 136897.8, 471784.1, 'New York'],\n       [162597.7, 151377.59, 443898.53, 'California'],\n       [153441.51, 101145.55, 407934.54, 'Florida'],\n       [144372.41, 118671.85, 383199.62, 'New York'],\n       [142107.34, 91391.77, 366168.42, 'Florida'],\n       [131876.9, 99814.71, 362861.36, 'New York'],\n       [134615.46, 147198.87, 127716.82, 'California'],\n       [130298.13, 145530.06, 323876.68, 'Florida'],\n       [120542.52, 148718.95, 311613.29, 'New York'],\n       [123334.88, 108679.17, 304981.62, 'California'],\n       [101913.08, 110594.11, 229160.95, 'Florida'],\n       [100671.96, 91790.61, 249744.55, 'California'],\n       [93863.75, 127320.38, 249839.44, 'Florida'],\n       [91992.39, 135495.07, 252664.93, 'California'],\n       [119943.24, 156547.42, 256512.92, 'Florida'],\n       [114523.61, 122616.84, 261776.23, 'New York'],\n       [78013.11, 121597.55, 264346.06, 'California'],\n       [94657.16, 145077.58, 282574.31, 'New York'],\n       [91749.16, 114175.79, 294919.57, 'Florida'],\n       [86419.7, 153514.11, 0.0, 'New York'],\n       [76253.86, 113867.3, 298664.47, 'California'],\n       [78389.47, 153773.43, 299737.29, 'New York'],\n       [73994.56, 122782.75, 303319.26, 'Florida'],\n       [67532.53, 105751.03, 304768.73, 'Florida'],\n       [77044.01, 99281.34, 140574.81, 'New York'],\n       [64664.71, 139553.16, 137962.62, 'California'],\n       [75328.87, 144135.98, 134050.07, 'Florida'],\n       [72107.6, 127864.55, 353183.81, 'New York'],\n       [66051.52, 182645.56, 118148.2, 'Florida'],\n       [65605.48, 153032.06, 107138.38, 'New York'],\n       [61994.48, 115641.28, 91131.24, 'Florida'],\n       [61136.38, 152701.92, 88218.23, 'New York'],\n       [63408.86, 129219.61, 46085.25, 'California'],\n       [55493.95, 103057.49, 214634.81, 'Florida'],\n       [46426.07, 157693.92, 210797.67, 'California'],\n       [46014.02, 85047.44, 205517.64, 'New York'],\n       [28663.76, 127056.21, 201126.82, 'Florida'],\n       [44069.95, 51283.14, 197029.42, 'California'],\n       [20229.59, 65947.93, 185265.1, 'New York'],\n       [38558.51, 82982.09, 174999.3, 'California'],\n       [28754.33, 118546.05, 172795.67, 'California'],\n       [27892.92, 84710.77, 164470.71, 'Florida'],\n       [23640.93, 96189.63, 148001.11, 'California'],\n       [15505.73, 127382.3, 35534.17, 'New York'],\n       [22177.74, 154806.14, 28334.72, 'California'],\n       [1000.23, 124153.04, 1903.93, 'New York'],\n       [1315.46, 115816.21, 297114.46, 'Florida'],\n       [0.0, 135426.92, 0.0, 'California'],\n       [542.05, 51743.15, 0.0, 'New York'],\n       [0.0, 116983.8, 45173.06, 'California']], dtype=object)"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "ct = ColumnTransformer(transformers=[('encodedState', OneHotEncoder(), [3])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.0, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n       [1.0, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n       [0.0, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n       [0.0, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n       [0.0, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n       [0.0, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n       [1.0, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n       [0.0, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n       [0.0, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n       [1.0, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n       [0.0, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n       [1.0, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n       [0.0, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n       [1.0, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n       [0.0, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n       [0.0, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n       [1.0, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n       [0.0, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n       [0.0, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n       [0.0, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n       [1.0, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n       [0.0, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n       [0.0, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n       [0.0, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n       [0.0, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n       [1.0, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n       [0.0, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n       [0.0, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n       [0.0, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n       [0.0, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n       [0.0, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n       [0.0, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n       [1.0, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n       [0.0, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n       [1.0, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n       [0.0, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n       [0.0, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n       [1.0, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n       [0.0, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n       [1.0, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n       [1.0, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n       [0.0, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n       [1.0, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n       [0.0, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n       [1.0, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n       [0.0, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n       [0.0, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n       [1.0, 0.0, 0.0, 0.0, 135426.92, 0.0],\n       [0.0, 0.0, 1.0, 542.05, 51743.15, 0.0],\n       [1.0, 0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the first column\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.0, 1.0, 165349.2, 136897.8, 471784.1],\n       [0.0, 0.0, 162597.7, 151377.59, 443898.53],\n       [1.0, 0.0, 153441.51, 101145.55, 407934.54],\n       [0.0, 1.0, 144372.41, 118671.85, 383199.62],\n       [1.0, 0.0, 142107.34, 91391.77, 366168.42],\n       [0.0, 1.0, 131876.9, 99814.71, 362861.36],\n       [0.0, 0.0, 134615.46, 147198.87, 127716.82],\n       [1.0, 0.0, 130298.13, 145530.06, 323876.68],\n       [0.0, 1.0, 120542.52, 148718.95, 311613.29],\n       [0.0, 0.0, 123334.88, 108679.17, 304981.62],\n       [1.0, 0.0, 101913.08, 110594.11, 229160.95],\n       [0.0, 0.0, 100671.96, 91790.61, 249744.55],\n       [1.0, 0.0, 93863.75, 127320.38, 249839.44],\n       [0.0, 0.0, 91992.39, 135495.07, 252664.93],\n       [1.0, 0.0, 119943.24, 156547.42, 256512.92],\n       [0.0, 1.0, 114523.61, 122616.84, 261776.23],\n       [0.0, 0.0, 78013.11, 121597.55, 264346.06],\n       [0.0, 1.0, 94657.16, 145077.58, 282574.31],\n       [1.0, 0.0, 91749.16, 114175.79, 294919.57],\n       [0.0, 1.0, 86419.7, 153514.11, 0.0],\n       [0.0, 0.0, 76253.86, 113867.3, 298664.47],\n       [0.0, 1.0, 78389.47, 153773.43, 299737.29],\n       [1.0, 0.0, 73994.56, 122782.75, 303319.26],\n       [1.0, 0.0, 67532.53, 105751.03, 304768.73],\n       [0.0, 1.0, 77044.01, 99281.34, 140574.81],\n       [0.0, 0.0, 64664.71, 139553.16, 137962.62],\n       [1.0, 0.0, 75328.87, 144135.98, 134050.07],\n       [0.0, 1.0, 72107.6, 127864.55, 353183.81],\n       [1.0, 0.0, 66051.52, 182645.56, 118148.2],\n       [0.0, 1.0, 65605.48, 153032.06, 107138.38],\n       [1.0, 0.0, 61994.48, 115641.28, 91131.24],\n       [0.0, 1.0, 61136.38, 152701.92, 88218.23],\n       [0.0, 0.0, 63408.86, 129219.61, 46085.25],\n       [1.0, 0.0, 55493.95, 103057.49, 214634.81],\n       [0.0, 0.0, 46426.07, 157693.92, 210797.67],\n       [0.0, 1.0, 46014.02, 85047.44, 205517.64],\n       [1.0, 0.0, 28663.76, 127056.21, 201126.82],\n       [0.0, 0.0, 44069.95, 51283.14, 197029.42],\n       [0.0, 1.0, 20229.59, 65947.93, 185265.1],\n       [0.0, 0.0, 38558.51, 82982.09, 174999.3],\n       [0.0, 0.0, 28754.33, 118546.05, 172795.67],\n       [1.0, 0.0, 27892.92, 84710.77, 164470.71],\n       [0.0, 0.0, 23640.93, 96189.63, 148001.11],\n       [0.0, 1.0, 15505.73, 127382.3, 35534.17],\n       [0.0, 0.0, 22177.74, 154806.14, 28334.72],\n       [0.0, 1.0, 1000.23, 124153.04, 1903.93],\n       [1.0, 0.0, 1315.46, 115816.21, 297114.46],\n       [0.0, 0.0, 0.0, 135426.92, 0.0],\n       [0.0, 1.0, 542.05, 51743.15, 0.0],\n       [0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[103015.20159796 132582.27760816 132447.73845175  71976.09851259\n 178537.48221054 116161.24230163  67851.69209676  98791.73374688\n 113969.43533012 167921.0656955 ]\n"
    }
   ],
   "source": [
    "# Fit the Linear Reg to the training data set\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "# Predict test set\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[103282.38 144259.4  146121.95  77798.83 191050.39 105008.31  81229.06\n  97483.56 110352.25 166187.94]\n"
    }
   ],
   "source": [
    "# Checking against test set\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Score: 0.9501847627493607\nModel slope: [-9.59284160e+02  6.99369053e+02  7.73467193e-01  3.28845975e-02\n  3.66100259e-02]\nModel intercept: 42554.16761776614\n"
    }
   ],
   "source": [
    "# coefficient of determination R^2 of the prediction\n",
    "print(\"Score: \", regressor.score(X_train, y_train), sep=\"\")\n",
    "# an array of weights estimated by linear regression\n",
    "# contain the coefficients for the prediction of each target\n",
    "print(\"Model slope: \",  regressor.coef_, sep=\"\")\n",
    "# Independent term in the linear model\n",
    "print(\"Model intercept: \", regressor.intercept_, sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Backward elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.regression.linear_model as sm \n",
    "X = np.append(arr = np.ones((50,1)).astype(int), values = X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.951\nModel:                            OLS   Adj. R-squared:                  0.945\nMethod:                 Least Squares   F-statistic:                     169.9\nDate:                Sat, 13 Jun 2020   Prob (F-statistic):           1.34e-27\nTime:                        12:43:17   Log-Likelihood:                -525.38\nNo. Observations:                  50   AIC:                             1063.\nDf Residuals:                      44   BIC:                             1074.\nDf Model:                           5                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       5.013e+04   6884.820      7.281      0.000    3.62e+04     6.4e+04\nx1           198.7888   3371.007      0.059      0.953   -6595.030    6992.607\nx2           -41.8870   3256.039     -0.013      0.990   -6604.003    6520.229\nx3             0.8060      0.046     17.369      0.000       0.712       0.900\nx4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\nx5             0.0270      0.017      1.574      0.123      -0.008       0.062\n==============================================================================\nOmnibus:                       14.782   Durbin-Watson:                   1.283\nProb(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\nSkew:                          -0.948   Prob(JB):                     2.41e-05\nKurtosis:                       5.572   Cond. No.                     1.45e+06\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.45e+06. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\"\"\"",
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Sat, 13 Jun 2020</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>12:43:17</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1074.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td> 5.013e+04</td> <td> 6884.820</td> <td>    7.281</td> <td> 0.000</td> <td> 3.62e+04</td> <td>  6.4e+04</td>\n</tr>\n<tr>\n  <th>x1</th>    <td>  198.7888</td> <td> 3371.007</td> <td>    0.059</td> <td> 0.953</td> <td>-6595.030</td> <td> 6992.607</td>\n</tr>\n<tr>\n  <th>x2</th>    <td>  -41.8870</td> <td> 3256.039</td> <td>   -0.013</td> <td> 0.990</td> <td>-6604.003</td> <td> 6520.229</td>\n</tr>\n<tr>\n  <th>x3</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.369</td> <td> 0.000</td> <td>    0.712</td> <td>    0.900</td>\n</tr>\n<tr>\n  <th>x4</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132</td> <td>    0.078</td>\n</tr>\n<tr>\n  <th>x5</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008</td> <td>    0.062</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>14.782</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.266</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>1.45e+06</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.45e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "X_backward = X[:,[0,1,2,3,4,5]]\n",
    "X_backward = np.array(X_backward, dtype=float)\n",
    "regressor_OLS = sm.OLS(endog = y, exog= X_backward).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.951\nModel:                            OLS   Adj. R-squared:                  0.946\nMethod:                 Least Squares   F-statistic:                     217.2\nDate:                Sat, 13 Jun 2020   Prob (F-statistic):           8.49e-29\nTime:                        12:43:17   Log-Likelihood:                -525.38\nNo. Observations:                  50   AIC:                             1061.\nDf Residuals:                      45   BIC:                             1070.\nDf Model:                           4                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       5.011e+04   6647.870      7.537      0.000    3.67e+04    6.35e+04\nx1           220.1585   2900.536      0.076      0.940   -5621.821    6062.138\nx2             0.8060      0.046     17.606      0.000       0.714       0.898\nx3            -0.0270      0.052     -0.523      0.604      -0.131       0.077\nx4             0.0270      0.017      1.592      0.118      -0.007       0.061\n==============================================================================\nOmnibus:                       14.758   Durbin-Watson:                   1.282\nProb(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\nSkew:                          -0.948   Prob(JB):                     2.53e-05\nKurtosis:                       5.563   Cond. No.                     1.40e+06\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.4e+06. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\"\"\"",
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Sat, 13 Jun 2020</td> <th>  Prob (F-statistic):</th> <td>8.49e-29</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>12:43:17</td>     <th>  Log-Likelihood:    </th> <td> -525.38</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td> 5.011e+04</td> <td> 6647.870</td> <td>    7.537</td> <td> 0.000</td> <td> 3.67e+04</td> <td> 6.35e+04</td>\n</tr>\n<tr>\n  <th>x1</th>    <td>  220.1585</td> <td> 2900.536</td> <td>    0.076</td> <td> 0.940</td> <td>-5621.821</td> <td> 6062.138</td>\n</tr>\n<tr>\n  <th>x2</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.606</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n</tr>\n<tr>\n  <th>x3</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.523</td> <td> 0.604</td> <td>   -0.131</td> <td>    0.077</td>\n</tr>\n<tr>\n  <th>x4</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.592</td> <td> 0.118</td> <td>   -0.007</td> <td>    0.061</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>14.758</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.172</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.53e-05</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 5.563</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "# x2 P>|t| = 0.990, removing x2\n",
    "X_backward = X[:,[0,1,3,4,5]]\n",
    "X_backward = np.array(X_backward, dtype=float)\n",
    "regressor_OLS = sm.OLS(endog = y, exog= X_backward).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.951\nModel:                            OLS   Adj. R-squared:                  0.948\nMethod:                 Least Squares   F-statistic:                     296.0\nDate:                Sat, 13 Jun 2020   Prob (F-statistic):           4.53e-30\nTime:                        12:43:17   Log-Likelihood:                -525.39\nNo. Observations:                  50   AIC:                             1059.\nDf Residuals:                      46   BIC:                             1066.\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\nx1             0.8057      0.045     17.846      0.000       0.715       0.897\nx2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\nx3             0.0272      0.016      1.655      0.105      -0.006       0.060\n==============================================================================\nOmnibus:                       14.838   Durbin-Watson:                   1.282\nProb(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\nSkew:                          -0.949   Prob(JB):                     2.21e-05\nKurtosis:                       5.586   Cond. No.                     1.40e+06\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.4e+06. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\"\"\"",
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Sat, 13 Jun 2020</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>12:43:17</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n</tr>\n<tr>\n  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n</tr>\n<tr>\n  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n</tr>\n<tr>\n  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "# x1 P>|t| = 0.940, removing x1\n",
    "X_backward = X[:,[0,3,4,5]]\n",
    "X_backward = np.array(X_backward, dtype=float)\n",
    "regressor_OLS = sm.OLS(endog = y, exog= X_backward).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.950\nModel:                            OLS   Adj. R-squared:                  0.948\nMethod:                 Least Squares   F-statistic:                     450.8\nDate:                Sat, 13 Jun 2020   Prob (F-statistic):           2.16e-31\nTime:                        12:43:17   Log-Likelihood:                -525.54\nNo. Observations:                  50   AIC:                             1057.\nDf Residuals:                      47   BIC:                             1063.\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\nx1             0.7966      0.041     19.266      0.000       0.713       0.880\nx2             0.0299      0.016      1.927      0.060      -0.001       0.061\n==============================================================================\nOmnibus:                       14.677   Durbin-Watson:                   1.257\nProb(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\nSkew:                          -0.939   Prob(JB):                     2.54e-05\nKurtosis:                       5.575   Cond. No.                     5.32e+05\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 5.32e+05. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\"\"\"",
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Sat, 13 Jun 2020</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>12:43:17</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n</tr>\n<tr>\n  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n</tr>\n<tr>\n  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "# x1 P>|t| = 0.602, removing x2\n",
    "X_backward = X[:,[0,3,5]]\n",
    "X_backward = np.array(X_backward, dtype=float)\n",
    "regressor_OLS = sm.OLS(endog = y, exog= X_backward).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.947\nModel:                            OLS   Adj. R-squared:                  0.945\nMethod:                 Least Squares   F-statistic:                     849.8\nDate:                Sat, 13 Jun 2020   Prob (F-statistic):           3.50e-32\nTime:                        12:43:17   Log-Likelihood:                -527.44\nNo. Observations:                  50   AIC:                             1059.\nDf Residuals:                      48   BIC:                             1063.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\nx1             0.8543      0.029     29.151      0.000       0.795       0.913\n==============================================================================\nOmnibus:                       13.727   Durbin-Watson:                   1.116\nProb(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\nSkew:                          -0.911   Prob(JB):                     9.44e-05\nKurtosis:                       5.361   Cond. No.                     1.65e+05\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.65e+05. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\"\"\"",
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.947</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   849.8</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Sat, 13 Jun 2020</td> <th>  Prob (F-statistic):</th> <td>3.50e-32</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>12:43:17</td>     <th>  Log-Likelihood:    </th> <td> -527.44</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1063.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td> 4.903e+04</td> <td> 2537.897</td> <td>   19.320</td> <td> 0.000</td> <td> 4.39e+04</td> <td> 5.41e+04</td>\n</tr>\n<tr>\n  <th>x1</th>    <td>    0.8543</td> <td>    0.029</td> <td>   29.151</td> <td> 0.000</td> <td>    0.795</td> <td>    0.913</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>13.727</td> <th>  Durbin-Watson:     </th> <td>   1.116</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.536</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td>-0.911</td> <th>  Prob(JB):          </th> <td>9.44e-05</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 5.361</td> <th>  Cond. No.          </th> <td>1.65e+05</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.65e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "# x1 P>|t| = 0.060, removing x2\n",
    "X_backward = X[:,[0,3]]\n",
    "X_backward = np.array(X_backward, dtype=float)\n",
    "regressor_OLS = sm.OLS(endog = y, exog= X_backward).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not that we have new X dataset, Splitting data into test and train\n",
    "X_trainBackEli, X_testBackEli, y_trainBackEli, y_testBackEli = train_test_split(X_backward, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression fit\n",
    "regressor_backward = LinearRegression()\n",
    "regressor_backward.fit(X_trainBackEli, y_trainBackEli)\n",
    "# predict\n",
    "y_predBackEli = regressor_backward.predict(X_testBackEli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[104667.27805998 134150.83410578 135207.80019517  72170.54428856\n 179090.58602508 109824.77386586  65644.27773757 100481.43277139\n 111431.75202432 169438.14843539]\n"
    }
   ],
   "source": [
    "\n",
    "print(y_predBackEli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[103282.38 144259.4  146121.95  77798.83 191050.39 105008.31  81229.06\n  97483.56 110352.25 166187.94]\n"
    }
   ],
   "source": [
    "print(y_testBackEli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model slope: [0.        0.8516228]\nModel intercept: 48416.297661385055\n"
    }
   ],
   "source": [
    "# an array of weights estimated by linear regression\n",
    "# contain the coefficients for the prediction of each target\n",
    "print(\"Model slope: \",  regressor_backward.coef_, sep=\"\")\n",
    "# Independent term in the linear model\n",
    "print(\"Model intercept: \", regressor_backward.intercept_, sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitvenvvenvad8c4df3ad5a45bb9181e3f8d0edf16a",
   "display_name": "Python 3.7.7 64-bit ('.venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}